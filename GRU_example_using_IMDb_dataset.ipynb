{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXhKQL1uXWo+9e9fSWEjQl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyaTareekAhmmeed/Deep-Neural-Network/blob/main/GRU_example_using_IMDb_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ge5Rs_WkUyyF"
      },
      "outputs": [],
      "source": [
        "#GRU is faster training but less accuracy than LSTM\n",
        "#imdb is dataset for movies reviews contain of review and its sentiment analysis "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb #importing our data\n",
        "from keras.layers import GRU, LSTM,  Activation\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "2W1oegyEYSnC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = 30000 #num of words used from dataset \n",
        "maxlen = 300 #maxlen in each pad = 300 word\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = num_words) #loading data\n",
        "\n",
        "# pad the sequences with zeros\n",
        "# padding parameter is set to 'post' => 0's are appended to end of sequences this mean \"dependenceon previous state is small (not fully dependanton post state) unlike LSTM\"\n",
        "X_train = pad_sequences(X_train, maxlen = maxlen, padding = 'post')\n",
        "X_test = pad_sequences(X_test, maxlen = maxlen, padding = 'post')\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape + (1,))\n",
        "X_test = X_test.reshape(X_test.shape + (1,))\n",
        "\n",
        "def gru_model():\n",
        "  model = Sequential()\n",
        "  model.add(GRU(50, input_shape = (300,1), return_sequences = True)) #input_shape = (300,1) 300 mean num of words and 1 cuz it is 1D data\n",
        "  model.add(GRU(1, return_sequences = False))\n",
        "  model.add(Activation('sigmoid')) #last layer must be activated \n",
        "  \n",
        "  #compile our model\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy']) #loss = 'binary_crossentropy' cuz it has only 2 classes \n",
        "  return model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grVxUjRMZot4",
        "outputId": "4731da75-fbd6-480a-a1e7-0e4b9d47ee21"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = gru_model()\n",
        "model.fit(X_train, y_train, batch_size = 100, epochs = 30, verbose = 1)\n",
        "\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j8I5vWzavcY",
        "outputId": "62410a20-8139-4362-8ee5-fb6855b72e27"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "250/250 [==============================] - 51s 192ms/step - loss: 0.6932 - accuracy: 0.5043\n",
            "Epoch 2/30\n",
            "250/250 [==============================] - 47s 188ms/step - loss: 0.6921 - accuracy: 0.5148\n",
            "Epoch 3/30\n",
            "250/250 [==============================] - 48s 192ms/step - loss: 0.6916 - accuracy: 0.5126\n",
            "Epoch 4/30\n",
            "250/250 [==============================] - 47s 187ms/step - loss: 0.6906 - accuracy: 0.5144\n",
            "Epoch 5/30\n",
            "250/250 [==============================] - 55s 221ms/step - loss: 0.6893 - accuracy: 0.5212\n",
            "Epoch 6/30\n",
            "250/250 [==============================] - 54s 216ms/step - loss: 0.6885 - accuracy: 0.5220\n",
            "Epoch 7/30\n",
            "250/250 [==============================] - 56s 224ms/step - loss: 0.6891 - accuracy: 0.5204\n",
            "Epoch 8/30\n",
            "250/250 [==============================] - 53s 211ms/step - loss: 0.6879 - accuracy: 0.5210\n",
            "Epoch 9/30\n",
            "250/250 [==============================] - 54s 215ms/step - loss: 0.6883 - accuracy: 0.5174\n",
            "Epoch 10/30\n",
            "250/250 [==============================] - 51s 204ms/step - loss: 0.6882 - accuracy: 0.5216\n",
            "Epoch 11/30\n",
            "250/250 [==============================] - 54s 216ms/step - loss: 0.6876 - accuracy: 0.5236\n",
            "Epoch 12/30\n",
            "250/250 [==============================] - 54s 218ms/step - loss: 0.6901 - accuracy: 0.5179\n",
            "Epoch 13/30\n",
            "250/250 [==============================] - 49s 197ms/step - loss: 0.6882 - accuracy: 0.5236\n",
            "Epoch 14/30\n",
            "250/250 [==============================] - 47s 189ms/step - loss: 0.6875 - accuracy: 0.5206\n",
            "Epoch 15/30\n",
            "250/250 [==============================] - 46s 185ms/step - loss: 0.6866 - accuracy: 0.5270\n",
            "Epoch 16/30\n",
            "250/250 [==============================] - 48s 190ms/step - loss: 0.6868 - accuracy: 0.5219\n",
            "Epoch 17/30\n",
            "250/250 [==============================] - 47s 186ms/step - loss: 0.6868 - accuracy: 0.5238\n",
            "Epoch 18/30\n",
            "250/250 [==============================] - 47s 187ms/step - loss: 0.6857 - accuracy: 0.5280\n",
            "Epoch 19/30\n",
            "250/250 [==============================] - 47s 188ms/step - loss: 0.6861 - accuracy: 0.5276\n",
            "Epoch 20/30\n",
            "250/250 [==============================] - 47s 187ms/step - loss: 0.6854 - accuracy: 0.5280\n",
            "Epoch 21/30\n",
            "250/250 [==============================] - 48s 190ms/step - loss: 0.6852 - accuracy: 0.5274\n",
            "Epoch 22/30\n",
            "250/250 [==============================] - 47s 187ms/step - loss: 0.6856 - accuracy: 0.5250\n",
            "Epoch 23/30\n",
            "250/250 [==============================] - 47s 187ms/step - loss: 0.6847 - accuracy: 0.5268\n",
            "Epoch 24/30\n",
            "250/250 [==============================] - 46s 186ms/step - loss: 0.6851 - accuracy: 0.5276\n",
            "Epoch 25/30\n",
            "250/250 [==============================] - 47s 186ms/step - loss: 0.6848 - accuracy: 0.5275\n",
            "Epoch 26/30\n",
            "250/250 [==============================] - 48s 191ms/step - loss: 0.6843 - accuracy: 0.5264\n",
            "Epoch 27/30\n",
            "250/250 [==============================] - 46s 186ms/step - loss: 0.6844 - accuracy: 0.5250\n",
            "Epoch 28/30\n",
            "250/250 [==============================] - 46s 186ms/step - loss: 0.6839 - accuracy: 0.5277\n",
            "Epoch 29/30\n",
            "250/250 [==============================] - 46s 186ms/step - loss: 0.6844 - accuracy: 0.5260\n",
            "Epoch 30/30\n",
            "250/250 [==============================] - 48s 190ms/step - loss: 0.6833 - accuracy: 0.5285\n",
            "Accuracy: 52.23%\n"
          ]
        }
      ]
    }
  ]
}